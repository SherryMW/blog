---
article: false
---

# Coze

官网：[https://www.coze.cn/home](https://www.coze.cn/home)

Coze（中文名 “扣子”）是字节跳动推出的零代码 / 低代码 AI 智能体开发平台，支持全技能用户快速构建、测试并部署生成式 AI 应用，核心优势是可视化拖拽、多模型接入、插件与知识库扩展、跨渠道发布，覆盖对话助手、流程自动化、数据处理等场景

## 提示词

Prompt（提示词） 是用户输入给 AI 模型（比如聊天机器人、绘画生成器、写作工具等）的指令、问题或描述，目的是引导 AI 生成符合需求的输出内容

### 核心特点

- 针对性：要明确告诉 AI 你想要什么，比如 “写一篇关于春天的散文”、“用 Python 写一个计算圆面积的程序”

- 可操作性：包含关键信息（如主题、风格、格式、字数），避免模糊表述  
  模糊例子：“写点东西” → AI 无法判断方向；  
  清晰例子：“写一篇 200 字左右、温暖治愈风格的春日公园短文” → AI 能精准响应

- 适配性：不同 AI 模型对提示词的偏好不同，比如绘画 AI 需要强调画面元素（色彩、构图、人物动作），而写作 AI 需要强调文体和语气

### 常见类型

- 问答类：直接提问，比如 “什么是人工智能？”“解释一下牛顿第一定律”

- 创作类：要求生成文字、图像等内容，比如 “写一首关于星空的现代诗”、“生成一张赛博朋克风格的城市夜景图”

- 指令类：要求 AI 完成特定任务，比如 “把这段英文翻译成中文”、“帮我修改这篇演讲稿的逻辑结构”

- 角色扮演类：设定 AI 的身份，比如 “请你扮演一名小学科学老师，给我讲解为什么天是蓝色的”

### 写好提示词的小技巧

- 明确需求：先定主题、再定风格、最后定细节

- 使用限定词：比如 “正式书面语”、“口语化”、“100 字以内”、“带举例”

- 分段指令：复杂需求可以分点说，比如 “1. 主题：低碳生活；2. 受众：中学生；3. 形式：倡议书；4. 字数：300 字左右”

### 实战演练-高情商职场回复助手

场景：职场常见问题，同事把他的工作丢给我，如果直接拒绝显得不近人情，如果接受又会给自己增加工作负担

业务需求：《高情商职场回复助手》

目标：职场沟通问题解决方案

主题：帮我拒绝同事的额外工作请求

创建智能体：

![](https://img.sherry4869.com/blog/coding/ai/coze/1.png)

编写提示词：

![](https://img.sherry4869.com/blog/coding/ai/coze/2.png)

```markdown
# 角色
你是⼀位经验丰富的沟通专家，拥有10年职场历练，在各类职场场景中都能游刃有余
尤其擅长撰写高情商、得体且有效的沟通文本，在拒绝请求时，能巧妙地平衡关系与边界

## 技能
### 技能 1: 语⽓把控
1. 以积极、友好的话语作为开头，营造融洽氛围
2. 表达观点时，以“我”为主语阐述自身限制
3. 杜绝使用指责性、命令式的语言
### 技能 2: 内容构建
1. 率先表达对对方请求的理解以及诚挚的感谢
2. 清晰、明确地说明自身存在的限制
3. 根据实际情况，提供切实可⾏的替代方案或合理建议
4. 以开放的态度，展望未来合作的可能性
### 技能 3: 关系维护
1. 适时、恰当地表达歉意
2. 真诚肯定对方工作的价值与贡献
3. 始终保持专业且友善的态度

## 输出格式
【开场寒暄】用积极友好的语言开启交流
【表达理解与感谢】清晰传达对对方的理解与感激
【委婉说明限制】明确阐述自身的限制条件
【提供替代方案】给出具体的替代办法或建议
【结尾祝福】以积极的话语结束对话，表达美好祝愿

## 限制
1. 避免使用“不”“拒绝”等直接的负面词汇
2. 不可过度承诺或给予虚假安慰
3. 不贬低对方请求的合理性
4. 不过多解释个人情况
```

## RAG

RAG(Retrieval-Augmented Generation 检索增强技术)，是 2020 年由 Facebook AI Research 提出的 AI 技术框架，核心是将检索系统与大语言模型（LLM）深度融合，让模型生成内容前先从外部知识库精准抓取相关信息作为“参考资料”，再基于这些事实性内容输出结果，无需全量重训模型即可解决知识过时、幻觉、领域能力不足等痛点，兼具低成本、高可控、可追溯的优势

### 为什么需要 RAG

通用大模型的三大固有缺陷，是 RAG 技术的核心驱动力：

|   缺陷   |                 表现                 |         影响          |
|:------:|:----------------------------------:|:-------------------:|
|  知识滞后  | 训练数据有时间截止点（如 GPT-4 截止 2023 年 10 月） | 无法回答实时事件、新政策、最新行业报告 |
|  输出幻觉  |      对未知领域生成 “看似合理但事实错误” 的内容       |  如虚构论文、错误数据，降低可信度   |
| 领域能力不足 |       缺乏垂直行业（医疗、法律、金融）的专业知识        |   回答泛化，无法满足行业精准需求   |

RAG 的核心思路是 **“知识存储与生成解耦”**：知识库可独立更新，生成模型专注语言能力，二者通过检索机制联动，实现 “低成本知识扩展 + 高可信度输出”

### 工作流程

RAG 的运行分为离线知识准备与在线检索生成两个核心阶段，覆盖从数据预处理到结果输出的全链路

**阶段 1：离线知识准备（知识库构建）**

目标是将**非结构化数据**转化为可高效检索的**向量**索引，核心步骤如下：

::: details 非结构化数据和向量的概念

|  数据类型  |              定义               |             典型示例             |       计算机处理难度       |
|:------:|:-----------------------------:|:----------------------------:|:-------------------:|
| 结构化数据  | 有固定格式、强 schema 约束，可直接存入关系型数据库 |    数据库表、Excel 表格、JSON/XML    |   低（可通过 SQL 直接查询）   |
| 半结构化数据 |   无严格 schema，但有标签 / 分隔符标记层级   |        日志文件、CSV、HTML         | 中（可通过正则、XPath 提取信息） |
| 非结构化数据 |  	无固定格式、无预设结构，以自然文本 / 多媒体为主   | PDF 文档、Word 报告、邮件、聊天记录、语音、图片 |   高（计算机无法直接识别语义）    |

RAG 处理的核心对象就是非结构化数据，比如一份医疗诊断报告、一篇技术论文、一份企业内部规章制度

这些数据的特点是：人类能看懂，但计算机只能看到 “一串字符 / 像素”，无法直接判断语义关联

---

在 RAG 技术中，我们说的向量全称是语义向量（Embedding Vector），它是解决非结构化数据语义理解的核心手段

向量是一串有序的数字列表，比如 `[0.23, -0.56, 1.89, -0.12, ...]`（长度可能是 768、1024 甚至更高）

这串数字的核心作用是 “用数学方式表达文本的语义” —— 语义越相似的文本，转化后的向量在高维空间中的距离越近

举个直观的例子：

- 文本 A：大语言模型的训练方法

- 文本 B：LLM 模型的训练流程

- 文本 C：小猫的喂养指南

向量 A 和向量 B 的余弦相似度很高（距离近）→ 计算机判定二者语义相关

向量 A 和向量 C 的余弦相似度很低（距离远）→ 计算机判定二者语义无关

专门的嵌入模型（Embedding Model） 负责把非结构化文本转化为向量，比如 Sentence-BERT、text-embedding-ada-002 等
:::

1. 文档预处理

    - 数据清洗：去除页眉页脚、空白行、重复内容，统一格式（PDF/Word/TXT→文本）

    - 语义分块（Chunking）：按语义逻辑拆分文档（避免过长冗余或过短断裂，常用 200-500 字符 / 块），提取元数据（文档名、页码、时间戳）用于后续过滤

2. 向量编码（Embedding）

    - 通过嵌入模型（如 Sentence-BERT、text-embedding-ada-002、Llama 3 Embedding）将每个文本块转化为高维向量（如 1024 维），向量的距离代表语义相似度

3. 向量存储与索引

    - 将向量与元数据存入向量数据库（如 Pinecone、Chroma、Milvus、FAISS），并构建索引（如 ANN 近似最近邻索引），支持毫秒级相似性检索

**阶段 2：在线检索生成（实时响应）**

1. 检索（Retrieval）

    - 查询编码：将用户问题通过同一嵌入模型转化为向量

    - 相似性匹配：向量数据库计算查询向量与库中向量的相似度（如余弦相似度、欧氏距离），返回 Top-K 个最相关的文本块（K 通常取 3-10）

    - 结果过滤：结合元数据（如时间、来源）筛选权威、最新的片段，排除噪声

2. 增强（Augmented）

    - 将用户问题、检索到的文本块、参考来源按 Prompt 模板重组，形成“问题 + 事实依据 + 指令（如‘基于以下资料生成准确回答，标注来源’）”的输入上下文

3. 生成（Generation）

    - 将增强后的上下文输入 LLM（如 GPT-4、Llama 3、通义千问），模型结合自身语言能力与外部事实生成回答

    - 输出优化：标注参考来源（如“来自文档 X 第 Y 页”），提升可追溯性，降低幻觉风险

### 构建知识库

![](https://img.sherry4869.com/blog/coding/ai/coze/3.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/4.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/5.png)

### 实战演练-LOL攻略知识库

**创建知识库：**

![](https://img.sherry4869.com/blog/coding/ai/coze/6.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/7.png)

上传：[英雄联盟攻略.pdf](https://img.sherry4869.com/blog/coding/ai/coze/%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F%E6%94%BB%E7%95%A5.pdf)

![](https://img.sherry4869.com/blog/coding/ai/coze/8.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/9.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/10.png)

**创建智能体：**

![](https://img.sherry4869.com/blog/coding/ai/coze/11.png)

系统提示词模板：

```markdown
# 角色
你叫小智，是⼀个英雄联盟游戏助手

## 技能
### 技能1：问题理解与回复分析
1. 认真理解从知识库中召回的内容和用户输入的问题，判断召回的内容是否是用户问题的答案
2. 如果你不能理解用户的问题，例如用户的问题太简单、不包含必要信息，此时你需要追问用户，直到你确定已理解了用户的问题和需求
### 技能2：回答用户问题
1. 如果知识库中没有召回任何内容，你的话术可以参考“对不起，我已经学习的知识中不包含问题相关内容，暂时无法提供答案
2. 如果召回的内容与用户问题有关，你应该只提取知识库中和问题提问相关的部分，整理并总结、整合并优化从知识库中召回的内容。你提供给用户的答案必须是精确且简洁的，无需注明答案的数据来源
3. 为用户提供准确而简洁的答案，同时你需要判断用户的问题属于下面列出来的哪个文档的内容，根据你的判断结果应该把相应的文档名称⼀起返回给用户

## 限制
1. 禁止回答的问题
对于这些禁止回答的问题，你可以根据用户问题想⼀个合适的话术
 - 个人隐私信息：包括但不限于真实姓名、电话号码、地址、账号密码等敏感信息
 - 违法、违规内容：包括但不限于政治敏感话题、色情、暴力、赌博、侵权等违反法律法规和道德伦理的内容
2. 你必须确保你的回答容易理解
3. 你应该用与用户输入相同的语言回答
4. 回答长度：不超过300字
5. ⼀定要使⽤ Markdown 格式回复
```

![](https://img.sherry4869.com/blog/coding/ai/coze/12.png)

## Function Calling

Function Calling（函数调用） 是大语言模型（LLM）的一项核心能力，指模型根据用户输入的自然语言指令，自动识别需要调用的外部函数 / 工具，并生成符合格式要求的函数调用参数，执行后再将结果整合到最终回答中的机制

简单来说，它解决了大语言模型 “只靠自身知识库无法处理实时数据、复杂计算、精准查询” 的痛点，让 LLM 能联动外部工具（如数据库、计算器、API、代码解释器等）完成更复杂的任务

![](https://img.sherry4869.com/blog/coding/ai/coze/13.png)

### 核心原理与流程

Function Calling 的典型执行步骤分为 4 步，以 Java 后端开发中 “查询 MongoDB 某张表的用户数量” 为例：

1. 定义函数元数据

   开发者需要提前告诉 LLM：有哪些函数可用、函数的作用、入参类型和说明。比如定义一个查询 MongoDB 用户数的函数：

    ```json
    {
      "name": "get_mongodb_user_count",
      "description": "查询MongoDB中指定集合的用户数量",
      "parameters": {
        "type": "object",
        "properties": {
          "db_name": {
            "type": "string",
            "description": "数据库名称，例如 user_db"
          },
          "collection_name": {
            "type": "string",
            "description": "集合名称，例如 user_info"
          }
        },
        "required": ["db_name", "collection_name"]
      }
    }
    ```

2. 用户输入触发函数调用需求

    用户提问：帮我查一下 `user_db` 数据库里 `user_info` 集合的用户总数

3. LLM 生成函数调用指令

    模型分析用户需求后，判断需要调用 `get_mongodb_user_count` 函数，并生成标准化的调用参数（通常是 JSON 格式）：

    ```json
    {
      "function": "get_mongodb_user_count",
      "parameters": {
        "db_name": "user_db",
        "collection_name": "user_info"
      }
    }
    ```

4. 执行函数 + 整合结果

    后端程序解析模型生成的函数调用指令，调用 MongoDB 的查询接口执行操作，得到结果（比如1250）

    程序将结果返回给 LLM，LLM 再用自然语言整理回答：`user_db` 数据库的 `user_info` 集合中，当前用户总数为1250人

### 关键特点与价值

1. 打破 LLM 的能力边界

    解决实时性问题：比如查询当天的天气、股票价格、RocketMQ 的消息队列长度

    解决精准计算 / 查询问题：比如执行 SQL 统计、复杂数学运算、调用 Java 接口获取业务数据

    解决工具联动问题：比如让 LLM 调用代码解释器运行 Java 代码，验证逻辑是否正确

2. 标准化与可复现

   函数调用的参数格式是固定的（如 JSON），便于程序解析和执行，避免了自然语言歧义导致的执行失败

3. 提升回答的准确性

    不再依赖 LLM 的 “记忆”，而是基于外部工具的真实数据，减少幻觉（比如不会再出现 “编造” 的数据库查询结果）

### 典型应用场景

作为 Java 后端工程师，你可以在以下场景中落地 Function Calling：

1. 智能运维助手

    调用函数查询服务器 CPU 使用率、RocketMQ 的消息堆积量、Spring Boot 应用的日志报错信息

2. 业务数据查询机器人

    联动 MySQL/MongoDB，让用户用自然语言提问（如 “查一下上个月的订单总额”），自动生成 SQL/Mongo 查询语句并执行

3. 自动化接口调用

    让 LLM 根据用户需求，自动调用内部的 Java API（如用户注册、订单创建接口），完成轻量化的业务操作

4. 代码辅助工具

    调用代码解释器函数，运行用户编写的 Java 代码片段，返回执行结果或报错信息

### 实战演练-AI旅行规划助手（利用已有插件）

![](https://img.sherry4869.com/blog/coding/ai/coze/14.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/15.png)

```markdown
# 角色
你是一位专业且贴心的旅游规划助手，擅长综合考虑时间、天气、价格、旅游景点等多元信息，为用户精心打造性价比超高的出行计划。不仅如此，还能凭借丰富的知识储备，深入解读旅行目的地的文化历史内涵

## 技能
### 技能 1: 深度探索名胜古迹历史
当用户提出旅行计划相关需求时，首先运用{search_url}搜索插件精准挖掘相关历史信息，并以生动、易懂的方式呈现给用户，帮助用户深度领略当地历史底蕴
### 技能 2: 精准搜索周边特色饭店
1. 当用户提出旅行计划相关需求时，借助{search_around}插件全面搜索相关信息
2. 对搜索到的饭店信息进行细致整理，涵盖饭店名称、详细地址、招牌特色菜品等关键内容，为用户提供清晰、实用的参考
===回复示例===
- 饭店名称：<饭店具体名称>
- 地址：<详细地址>
- 特色菜品：<列举几道特色菜品>
===示例结束===
### 技能 3: 实时掌握出行天气
1. 当用户提出旅行计划相关需求时，利用{DayWeather}插件获取目的地出行期间的准确天气状况
2. 若天气状况可能对旅行体验产生影响，依据天气特点，给出合理且人性化的出行日期调整建议
===回复示例===
- 预计出行期间天气状况: <具体天气描述>
- 基于天气情况，建议出行日期调整为: <具体日期>
===示例结束===
### 技能 4: 精细规划旅行费用预算
1. 根据用户提供的旅行计划相关信息，诸如目的地、出行时长、住宿要求等，通过{calculate}插件进行精确的费用预算
2. 费用预算全面覆盖交通、住宿、餐饮、景点门票等主要支出项目，确保用户对旅行开支有清晰的预估
===回复示例===
- 交通费用预算：<具体金额>
- 住宿费用预算：<具体金额>
- 餐饮费用预算：<具体金额>
- 景点门票费用预算：<具体金额>
- 总预算：<各项费用总和>
===示例结束===

## 输出格式
### 旅行计划输出示例
- 旅行目的地：<具体城市/地点>
- 地点文化历史：<描述名胜古迹历史>
- 出行时间：<开始日期 - 结束日期>
- 总预算：<具体金额>
- 天气情况：<具体天气信息描述>
- ⾏程安排：
    - 第 1 天：
        - 上午：<具体行程安排，详细说明参观景点及活动内容>
        - 中午：<推荐用餐饭店，简单介绍饭店特色>
        - 下午：<具体行程安排，突出重点活动>
        - 晚上：<推荐用餐饭店及活动安排，提供活动亮点介绍>
    - 第 2 天：
        - 上午：<具体行程安排，明确景点特色>
        - 中午：<推荐用餐饭店，提及招牌菜品>
        - 下午：<具体行程安排，强调体验感受>
        - 晚上：<推荐用餐饭店及活动安排，说明活动意义>
    - ……（按实际行程天数依次详细罗列）
- 特色饭店推荐：
    - <饭店 1 名称>：地址 - <详细地址>，特色菜品 - <列举菜品，并对特色菜品进行简单介绍>
    - <饭店 2 名称>：地址 - <详细地址>，特色菜品 - <列举菜品，说明菜品独特之处>
    - ……（如有多个饭店依次详细罗列）

## 限制
- 专注提供与旅行规划紧密相关的信息，坚决拒绝回答与旅行规划无关的话题
- 所输出的内容务必严格按照给定的格式进行组织，不得有任何偏离框架要求的情况
- 行程安排描述要做到简洁明了且重点突出，让用户能够快速把握行程要点
- 确保所有信息来源准确可靠，借助插件获取的信息需经过严谨的整理和筛选
- 请使用 Markdown 的 ^^ 形式清晰说明引用来源（若有）
```

在中间的【编排】-【技能】-【插件】添加要使用的插件后，左侧提示词里输入“`{`”就可以选择应用所添加的插件

![](https://img.sherry4869.com/blog/coding/ai/coze/16.png)

### 实战演练-天气插件助手（自定义开发）

什么时候需要自定义插件：

- 官方插件没有你想要的功能
- 想连接特定的第三方API服务
- 需要对接企业内部系统

![](https://img.sherry4869.com/blog/coding/ai/coze/17.png)

新建插件：

![](https://img.sherry4869.com/blog/coding/ai/coze/18.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/19.png)

```python
# 导⼊ Coze 运⾏时所需的 Args 类，⽤于获取输⼊参数和⽇志记录器
from runtime import Args
# 导⼊ requests 库，⽤于发送 HTTP 请求（调⽤天⽓ API）
import requests # 需要安装对应的库
# 定义插件的主⼊⼝函数 handler；Coze 平台会⾃动调⽤此函数
# 参数 args 是 Coze 传⼊的运⾏时上下⽂对象
# 返回值为 dict 类型，将作为插件的输出结果返回给 Agent
def handler(args: Args):
    """
    天⽓查询插件：
        根据城市地址查询天⽓信息，⽐如输⼊“北京“，输出{
                                                high:"⾼温 7℃",
                                                low:"低温 -1℃",
                                                weather:"晴",
                                                week:"星期⼆"
                                                }
    """
    # === 1. 解析输⼊ ===
    try:
        # 从 args.input 中获取 location 字段，并去除⾸尾空格（如⽤户输⼊ " 北京 "）
        # 注意：此处假设输⼊为对象属性访问（如 args.input.location），适⽤于 manifest 中声明了 location 字段的情况
        location = args.input.location.strip()
    except Exception:
        # 若获取 location 失败（如字段不存在、输⼊⾮对象等），设为空字符串
        location = ""
    # === 2. 城市编码映射（仅北京、天津，内置）===
    # 构建城市名称 → 天⽓ API 编码的映射字典（仅保留北京和天津两个城市，轻量且教学友好）
    city_code_map = {
        "北京": "101010100",   # 北京市的天⽓ API 编码
        "天津": "101030100"    # 天津市的天⽓ API 编码
    }
    # 根据⽤户输⼊的城市名，查找对应的编码；若找不到则返回 None
    city_code = city_code_map.get(location)
    # 不⽀持的城市（如输⼊“上海”或空字符串）→ 返回空值结构
    if not city_code:
        # 记录警告⽇志：提示该城市暂不⽀持（可在 Coze 后台查看）
        args.logger.warning(f"Unsupported location: '{location}'")
        # 返回标准化的空结果（所有字段为 None），保证输出结构⼀致
        return {
            "high": None,       # 最⾼温度
            "low": None,        # 最低温度
            "weather": None,    # 天⽓类型（如“晴”）
            "week": None        # 星期（如“星期⼆”）
        }
    # === 3. 调⽤天⽓ API ===
    # 拼接完整 API 请求 URL，替换 {city_code} 为实际城市编码
    url = f"http://t.weather.itboy.net/api/weather/city/{city_code}"
    
    try:
        # 发起 GET 请求，设置超时 5 秒（防⽌插件卡死）
        response = requests.get(url, timeout=5)
        # 若 HTTP 状态码⾮ 2xx，主动抛出异常（如 404、500 等）
        response.raise_for_status()
        # 将响应体解析为 JSON 字典（安全⽅式，避免使⽤危险的 eval()）
        data = response.json()
        # 检查 API 业务层返回状态码（该 API 约定 status=200 表示成功）
        if data.get("status") != 200:
            # 若业务状态异常（如城市编码错误），抛出⾃定义异常
            raise ValueError("Weather API returned non-200 status")
        # 从返回数据中提取「今⽇」天⽓预报（forecast 列表第 0 项即为当天）
        # 路径：data → forecast 数组 → 第 0 个元素
        forecast = data["data"]["forecast"][0]
        
        # 构造并返回天⽓基本信息字典
        return {
            "high": forecast["high"],     # 字符串，如 "⾼温 7℃"
            "low": forecast["low"],       # 字符串，如 "低温 -1℃"
            "weather": forecast["type"],  # 字符串，如 "晴"、"⼩⾬"
            "week": forecast["week"]      # 字符串，如 "星期⼆"
        }
    # 捕获所有可能的异常（⽹络错误、JSON 解析失败、字段缺失等）
    except Exception as e:
        # 记录错误⽇志，包含具体异常信息和请求城市，便于调试
        args.logger.error(f"Weather query failed for '{location}': {e}")
        # 统⼀返回空值结构，确保插件健壮性（不会因异常导致 Agent 崩溃）
        return {
            "high": None,
            "low": None,
            "weather": None,
            "week": None
        }
```

记得要在界面左下角的【依赖包】里安装【requests】依赖

![](https://img.sherry4869.com/blog/coding/ai/coze/20.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/21.png)

测试通过后右上角点击【发布】

创建天气查询助手智能体：

![](https://img.sherry4869.com/blog/coding/ai/coze/22.png)

在插件中选择我们自定义的【get_weather】插件：

![](https://img.sherry4869.com/blog/coding/ai/coze/23.png)

## 工作流

Coze 工作流是基于可视化界面的任务编排系统，通过节点拖拽与连接实现复杂业务逻辑，核心是有向无环图（DAG）结构，支持数据流驱动、条件分支、并行处理与错误恢复，适配 AI Agent 开发、数据处理、业务自动化等场景

### 核心概念与基础架构

本质定义：工作流由触发节点、处理节点、判断节点、工具节点、结束节点等组成，节点间通过数据流传递变量，形成闭环或线性执行链路

**两种核心类型：**

![](https://img.sherry4869.com/blog/coding/ai/coze/24.png)

### 核心节点类型与功能

| 节点分类 |            	代表节点             |                功能说明                 |         关键配置         |
|:----:|:----------------------------:|:-----------------------------------:|:--------------------:|
| 触发节点 |            Start             |      工作流入口，定义输入参数（必填 / 可选、默认值）      |   参数名称、类型、描述、是否必填    |
| 逻辑处理 |             LLM              |           调用大模型，处理文本生成、推理           | 模型选择、提示词、输出格式、工具调用权限 |
|      |            	Code             | 执行 Python/JavaScript 代码，处理复杂计算或数据转换 |   代码编辑、输入输出映射、依赖管理   |
|      |          Knowledge           |         从知识库召回数据，增强 LLM 上下文         |   知识库选择、召回策略、相似度阈值   |
| 决策判断 |           Selector           |       实现 if-else 多条件分支，支持嵌套判断       |   条件表达式、分支路径、默认分支    |
| 外部集成 |            Plugin            |         连接第三方服务（搜索、天气、飞书等）          |    插件选择、鉴权配置、参数映射    |
|      |           Workflow           |           嵌套调用子工作流，复用复杂流程           |    子工作流选择、输入参数传递     |
| 数据操作 | Add/Query/Update/Delete Data |            操作内置数据库或外部数据源            |     表名、字段映射、筛选条件     |
| 输出控制 |          End/Output          |            返回结果或输出到外部系统             |     结果变量引用、格式定义      |

### 开发与执行流程

**需求拆解与规划：**

- 需求拆解与规划

    - 明确目标：如 “生成小红书养生图文” 需拆分为主题输入→文案生成→图片生成→水印添加→输出

    - 设计流程：确定节点顺序、分支条件、数据流向，绘制 DAG 草图

- 创建与初始化工作流

    - 进入 Coze 开发平台→资源库→新建工作流，命名并添加描述

    - 配置 Start 节点：设置输入参数（如 “主题”“水印文本”），标记必填项并填写默认值

- 节点编排与配置

    - 拖拽节点到画布，按流程连线

    - 配置 LLM 节点：选择模型、编写提示词（如 “生成符合小红书风格的养生文案，包含标题、正文、标签”），设置输出格式为 JSON

    - 配置 Plugin 节点：选择 “图片生成插件”，传入文案中的关键词，设置图片尺寸与风格

    - 配置 Selector 节点：添加条件 “若图片数量> 1，则并行生成多张；否则生成单张”

- 变量管理与数据传递

    - 节点输入优先引用前序节点输出（如引用 LLM 生成的文案作为图片插件的关键词）

    - 全局变量存储会话级数据（如用户偏好），局部变量仅在当前节点有效

    - 使用 “变量聚合” 节点合并多节点输出，统一数据格式

- 调试与测试

    - 单步执行：逐步运行节点，查看日志与变量值，定位错误

    - 断点调试：在关键节点设置断点，检查数据是否符合预期

    - 异常处理：添加 “错误捕获” 节点，配置重试机制或降级策略（如插件调用失败时返回默认文案）

- 发布与触发

    - 发布工作流：保存并发布，生成 API 或 Webhook 地址

    - 触发方式：手动触发、定时任务（如每日生成热点报告）、API 调用（与外部系统集成）、事件驱动（如用户发送消息时触发 Chatflow）

**执行机制与数据流原理：**

- 执行顺序：按节点连线的有向路径执行，支持并行分支（如同时调用两个插件获取数据）与嵌套子工作流

- 数据传递规则

    - 节点输出自动存入变量池，后续节点通过 “引用” 方式获取

    - 变量类型支持字符串、数字、数组、对象，可通过 Code 节点转换格式

    - 条件节点根据变量值动态选择执行路径，实现流程灵活性

- 错误处理机制

    - 节点失败时，支持重试（设置次数与间隔）、跳过（执行默认分支）或终止（返回错误信息）

    - 日志系统记录每个节点的输入输出、执行状态与耗时，便于问题排查

### 实战演练-跨境电商答疑助手（对话流）

![](https://img.sherry4869.com/blog/coding/ai/coze/25.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/26.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/27.png)

创建对话流：

![](https://img.sherry4869.com/blog/coding/ai/coze/28.png)

![](https://img.sherry4869.com/blog/coding/ai/coze/29.png)

1. 开始节点

    作用：接收用户输入的问题

    实现方式：默认节点

2. 意图识别

    作用：判断用户输入的问题是否属于跨境电商知识范畴。主要三种选择 -> 打招呼（greeting）；找人工（human）；RAG检索

    实现方式：添加【插件】节点，该插件是用户自定义实现


//TODO

## 学习资料

黑马程序员：[https://www.bilibili.com/video/BV12omoB4ExF](https://www.bilibili.com/video/BV12omoB4ExF)